name: AI Multi-Platform Shorts Pipeline (Smart Scheduled)

on:
  workflow_dispatch:
    inputs:
      platforms:
        description: 'Platforms to upload to (comma-separated: youtube,tiktok,instagram,facebook)'
        required: false
        default: 'youtube'
      force_all:
        description: 'Force upload to all enabled platforms'
        required: false
        type: boolean
        default: false
      ignore_schedule:
        description: 'Ignore optimal timing and post immediately'
        required: false
        type: boolean
        default: false
  
  schedule:
    # 1. The Viral Slot (Friday 23:00 UTC)
    - cron: '0 23 * * 5'
    
    # 2. The Sunday Prep Slot (Sunday 21:00 UTC)
    - cron: '0 21 * * 0'
    
    # 3. The Mid-Week High (Thursday 22:00 UTC)
    - cron: '0 22 * * 4'
    
    # 4. The Consistency Slot (Wednesday 23:00 UTC)
    - cron: '0 23 * * 3'
    
    # 5. The Early Weekend Slot (Sunday 18:00 UTC)
    - cron: '0 18 * * 0'

# âœ… ADD THIS BLOCK TO FIX THE 403 ERROR
permissions:
  contents: write


jobs:
  build_and_upload:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }} # Needed to push changes back

      # âœ… NEW: Free up disk space
      - name: ðŸ§¹ Free up runner disk space
        run: |
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸ” RUNNER DISK SPACE - BEFORE CLEANUP"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          df -h / | grep -E "Filesystem|/dev/root"
          echo ""
          
          echo "ðŸ—‘ï¸ Removing unused system packages..."
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf /usr/local/share/boost
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          
          echo "ðŸ³ Cleaning Docker cache..."
          docker image prune -f || true
          
          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "âœ… RUNNER DISK SPACE - AFTER CLEANUP"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          df -h / | grep -E "Filesystem|/dev/root"
          echo ""
          echo "ðŸ’¾ Freed: ~3.5GB"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      - name: Validate secrets
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          HUGGINGFACE_API_KEY: ${{ secrets.HUGGINGFACE_API_KEY }}
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
        run: python .github/scripts/validate_secrets.py

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # âœ… MODIFIED: Added --no-cache-dir
      - name: Install Python packages (for scheduler check)
        run: |
          python -m pip install --upgrade pip --no-cache-dir
          pip install --no-cache-dir pytz

      - name: Restore episode tracking (Package 3)
        uses: actions/cache/restore@v4
        with:
          path: tmp/episode_tracking.json
          key: episode-tracking-${{ github.run_number }}
          restore-keys: |
            episode-tracking-

      - name: Restore next episode promise (CTA Continuity)
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache/restore@v4
        with:
          path: tmp/next_episode.json
          key: next-episode-promise-${{ github.run_number }}
          restore-keys: |
            next-episode-promise-

      - name: Restore performance data (Package 4)
        uses: actions/cache/restore@v4
        with:
          path: |
            tmp/content_performance.json
            tmp/delay_log.json
            tmp/retry_queue.json
            tmp/schedule_recommendations.json
          key: performance-data-${{ github.run_number }}
          restore-keys: |
            performance-data-

      - name: ðŸŽ¯ Check optimal posting time (ENHANCED)
        id: schedule_check
        env:
          IGNORE_SCHEDULE: ${{ github.event.inputs.ignore_schedule }}
          ENABLE_AUTO_ADJUSTMENT: ${{ vars.ENABLE_AUTO_ADJUSTMENT || 'true' }}
        run: python .github/scripts/optimal_scheduler.py
            
      - name: Load episode tracking (Package 3)
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          mkdir -p tmp
          if [ ! -f tmp/episode_tracking.json ]; then
            echo '{}' > tmp/episode_tracking.json
          fi

      - name: Display series information (Package 3)
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          echo "ðŸ“º SERIES INFO:"
          echo "   Series: ${{ steps.schedule_check.outputs.series }}"
          echo "   Episode: ${{ steps.schedule_check.outputs.episode_number }}"
          echo "   Content Type: ${{ steps.schedule_check.outputs.content_type }}"
          echo "   Target Completion: ${{ steps.schedule_check.outputs.target_completion }}"
          echo "   Predicted Completion: ${{ steps.schedule_check.outputs.predicted_completion }}"
          echo "â±ï¸  Scheduling Delay: ${{ steps.schedule_check.outputs.delay_minutes }} minutes"

      - name: Display scheduling decision (ENHANCED)
        run: |
          echo "ðŸ“… Current Time: ${{ steps.schedule_check.outputs.current_time }}"
          echo "ðŸŽ¯ Should Post: ${{ steps.schedule_check.outputs.should_post }}"
          echo "â­ Priority: ${{ steps.schedule_check.outputs.priority }}"
          echo "ðŸ“º Series: ${{ steps.schedule_check.outputs.series }}"
          echo "ðŸŽ¬ Episode: ${{ steps.schedule_check.outputs.episode_number }}"
          echo "ðŸŽ¯ Target Completion: ${{ steps.schedule_check.outputs.target_completion }}"
          echo "â±ï¸ Delay: ${{ steps.schedule_check.outputs.delay_minutes }} minutes"

      - name: Skip if not optimal time
        if: steps.schedule_check.outputs.should_post != 'true'
        run: |
          echo "â¸ï¸ Skipping run - not within optimal posting window"
          echo "ðŸ’¡ Next post: Check posting_schedule.json for upcoming slots"
          exit 0
          
      - name: Cache apt packages
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache@v4
        with:
          path: |
            /var/cache/apt/archives
            /var/lib/apt/lists
          key: ${{ runner.os }}-apt-${{ hashFiles('.github/workflows/ai_shorts_trending.yml') }}
          restore-keys: |
            ${{ runner.os }}-apt-

      # âœ… MODIFIED: Added apt-get clean
      - name: Install system deps
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            ffmpeg \
            libsm6 \
            libxext6 \
            imagemagick \
            fonts-dejavu-core \
            fonts-liberation \
            fonts-freefont-ttf \
            espeak-ng
          
          # Clean APT cache to save space
          sudo apt-get clean
          sudo rm -rf /var/lib/apt/lists/*
          
          echo "ðŸ“ Available fonts:"
          fc-list | grep -i dejavu | head -3
          fc-list | grep -i liberation | head -3

      - name: Cache Coqui models
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache@v4
        with:
          path: ~/.local/share/tts
          key: coqui-models-${{ runner.os }}

      - name: Make tmp folder
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          mkdir -p tmp
          chmod -R 777 tmp

      - name: Restore episode tracking (NEW)
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache/restore@v4
        with:
          path: tmp/episode_tracking.json
          key: episode-tracking-${{ github.run_number }}
          restore-keys: |
            episode-tracking-

      - name: Restore platform config
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache/restore@v4
        with:
          path: tmp/platform_config.json
          key: platform-config-${{ github.run_number }}
          restore-keys: |
            platform-config-

      - name: Restore playlist config
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache/restore@v4
        with:
          path: tmp/playlist_config.json
          key: playlist-config-${{ github.run_number }}
          restore-keys: |
            playlist-config-

      - name: Restore content history
        if: steps.schedule_check.outputs.should_post == 'true'
        uses: actions/cache/restore@v4
        with:
          path: tmp/content_history.json
          key: content-history-${{ github.run_number }}
          restore-keys: |
            content-history-

      # âœ… MODIFIED: Added --no-cache-dir
      - name: Install Python packages
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          python -m pip install --upgrade pip --no-cache-dir
          pip install --no-cache-dir -r requirements.txt

      - name: Fetch trending topics
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: python .github/scripts/fetch_trending.py

      - name: Generate trending topic & script (SERIES-AWARE)
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          SERIES_NAME: ${{ steps.schedule_check.outputs.series }}
          EPISODE_NUMBER: ${{ steps.schedule_check.outputs.episode_number }}
          CONTENT_TYPE: ${{ steps.schedule_check.outputs.content_type }}
        run: python .github/scripts/generate_trending_and_script.py

      - name: Generate TTS (HuggingFace Neural)
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          HUGGINGFACE_API_KEY: ${{ secrets.HUGGINGFACE_API_KEY }}
        run: python .github/scripts/generate_tts.py

      - name: Create video
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          HUGGINGFACE_API_KEY: ${{ secrets.HUGGINGFACE_API_KEY }}
        run: python .github/scripts/create_video.py

      - name: Generate thumbnail
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          HUGGINGFACE_API_KEY: ${{ secrets.HUGGINGFACE_API_KEY }}
        run: python .github/scripts/generate_thumbnail.py

      - name: Clean up temporary files
        if: steps.schedule_check.outputs.should_post == 'true'
        run: |
          find tmp -name "scene_*.jpg" -type f -delete || true
          rm -f tmp/short_ready.mp4 || true

      - name: Upload to YouTube (SERIES-AWARE)
        if: steps.schedule_check.outputs.should_post == 'true'
        env:
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
          SERIES_NAME: ${{ steps.schedule_check.outputs.series }}
          EPISODE_NUMBER: ${{ steps.schedule_check.outputs.episode_number }}
        run: python .github/scripts/upload_youtube.py

      - name: Increment episode counter (Package 3)
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        run: |
          python -c "
          import json, os
          series = '${{ steps.schedule_check.outputs.series }}'
          if series and series != 'none':
              tracking_file = 'tmp/episode_tracking.json'
              os.makedirs('tmp', exist_ok=True)
              try:
                  with open(tracking_file, 'r') as f:
                      tracking = json.load(f)
              except:
                  tracking = {}
              tracking[series] = tracking.get(series, 0) + 1
              with open(tracking_file, 'w') as f:
                  json.dump(tracking, f, indent=2)
              print(f'âœ… Episode counter incremented: {series} -> Episode {tracking[series]}')
          "

      - name: Track upload performance (Package 4)
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        run: python .github/scripts/track_performance.py

      - name: Track upload performance (Package 4)
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        run: python .github/scripts/track_performance.py
      
      - name: Find actual video file
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        id: find_video
        run: |
          if [ -f tmp/short.mp4 ]; then
            VIDEO_PATH="tmp/short.mp4"
          else
            VIDEO_PATH=$(find tmp -name "*.mp4" -type f | head -n 1)
          fi
          if [ -z "$VIDEO_PATH" ]; then echo "âŒ No video file found!"; exit 1; fi
          VIDEO_PATH=$(realpath "$VIDEO_PATH")
          echo "video_path=$VIDEO_PATH" >> $GITHUB_OUTPUT
          echo "video_name=$(basename $VIDEO_PATH)" >> $GITHUB_OUTPUT
          echo "âœ… Video validated: $VIDEO_PATH"
      
      - name: Prepare Make.com payload
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        id: makecom_prep
        run: |
          TITLE=$(jq -r '.title' tmp/script.json)
          DESCRIPTION=$(jq -r '.description' tmp/script.json)
          HASHTAGS=$(jq -r '.hashtags | join(" ")' tmp/script.json)
          VIDEO_PATH="${{ steps.find_video.outputs.video_path }}"
          VIDEO_SIZE=$(stat -c%s "$VIDEO_PATH" 2>/dev/null || stat -f%z "$VIDEO_PATH")
          YOUTUBE_URL=""
          if [ -f tmp/upload_history.json ]; then
            YOUTUBE_URL=$(jq -r '.[-1].shorts_url // ""' tmp/upload_history.json)
          fi
          cat > tmp/makecom_payload.json <<EOF
          {
            "title": "$TITLE",
            "description": "$DESCRIPTION",
            "hashtags": "$HASHTAGS",
            "series": "${{ steps.schedule_check.outputs.series }}",
            "episode": "${{ steps.schedule_check.outputs.episode_number }}",
            "video_name": "$(basename $VIDEO_PATH)",
            "video_size_mb": $(echo "scale=2; $VIDEO_SIZE/1024/1024" | bc),
            "workflow_run": "${{ github.run_number }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "youtube_url": "$YOUTUBE_URL"
          }
          EOF
          echo "âœ… Make.com payload prepared"

      - name: Upload video to Cloudinary for Make.com
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        id: upload_temp
        env:
          CLOUDINARY_CLOUD_NAME: ${{ secrets.CLOUDINARY_CLOUD_NAME }}
          CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
          CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
          VIDEO_TO_UPLOAD: ${{ steps.find_video.outputs.video_path }}
        run: |
          echo "ðŸ“¤ Uploading video to Cloudinary..."
          python .github/scripts/upload_to_cloudinary.py
          VIDEO_URL=$(cat tmp/video_url.txt)
          echo "video_url=$VIDEO_URL" >> $GITHUB_OUTPUT
          echo "âœ… Video URL: $VIDEO_URL"

      - name: Send to Make.com webhook
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        run: |
          PAYLOAD=$(cat tmp/makecom_payload.json)
          VIDEO_URL="${{ steps.upload_temp.outputs.video_url }}"
          VIDEO_NAME="${{ steps.find_video.outputs.video_name }}"
          curl -X POST "${{ secrets.MAKECOM_WEBHOOK_URL }}" \
            -H "Content-Type: application/json" \
            -d "{
              \"video_url\": \"$VIDEO_URL\",
              \"video_name\": \"$VIDEO_NAME\",
              \"metadata\": $PAYLOAD,
              \"artifact_url\": \"https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\",
              \"github\": {
                \"run_id\": \"${{ github.run_id }}\",
                \"run_number\": \"${{ github.run_number }}\",
                \"repository\": \"${{ github.repository }}\"
              }
            }"
          echo "âœ… Webhook sent to Make.com"

      - name: Organize YouTube playlists (SERIES-AWARE)
        if: success() && steps.schedule_check.outputs.should_post == 'true'
        env:
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
          SERIES_NAME: ${{ steps.schedule_check.outputs.series }}
        run: python .github/scripts/manage_playlists.py

      - name: Save episode tracking (Package 3)
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: tmp/episode_tracking.json
          key: episode-tracking-${{ github.run_number }}

      - name: Save next episode promise (CTA Continuity)
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: tmp/next_episode.json
          key: next-episode-promise-${{ github.run_number }}

      - name: Save performance data (Package 4)
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: |
            tmp/content_performance.json
            tmp/delay_log.json
            tmp/retry_queue.json
            tmp/schedule_recommendations.json
          key: performance-data-${{ github.run_number }}

      - name: Save platform config
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: tmp/platform_config.json
          key: platform-config-${{ github.run_number }}

      - name: Save playlist config
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: tmp/playlist_config.json
          key: playlist-config-${{ github.run_number }}

      - name: Save content history
        uses: actions/cache/save@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          path: tmp/content_history.json
          key: content-history-${{ github.run_number }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        with:
          name: latest-short-${{ github.run_number }}
          path: |
            tmp/*.mp4
            tmp/thumbnail.png
            tmp/script.json
            tmp/content_history.json
            tmp/playlist_config.json
            tmp/platform_config.json
            tmp/upload_history.json
            tmp/episode_tracking.json
            tmp/next_episode.json
            tmp/content_performance.json
            tmp/delay_log.json
            tmp/retry_queue.json
            tmp/schedule_recommendations.json
            tmp/voice.mp3
          retention-days: 30

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: error-logs-${{ github.run_number }}
          path: tmp/*.log
          retention-days: 7
      
      - name: ðŸ’¾ Persist State (Commit to Repo)
        if: always() && steps.schedule_check.outputs.should_post == 'true'
        run: |
          git config --global user.name 'GitHub Actions Scheduler'
          git config --global user.email 'actions@github.com'
          
          # Pull latest changes to avoid conflict
          git pull --rebase --autostash || true
          
          # Force add files (bypass .gitignore if tmp is ignored)
          git add -f tmp/episode_tracking.json || true
          git add -f tmp/next_episode.json || true
          git add -f tmp/content_history.json || true
          git add -f tmp/content_performance.json || true
          
          # Check if there is anything to commit
          if git diff --staged --quiet; then
            echo "âœ… No changes to state files."
          else
            git commit -m "ðŸ¤– Update Episode Counters & CTA Promises [skip ci]"
            git push
            echo "âœ… State preserved to repository"
          fi
          
      - name: Post-run summary (Package 3 & 4 ENHANCED)
        if: always()
        run: |
          echo "## ðŸ“Š Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Time:** ${{ steps.schedule_check.outputs.current_time }}" >> $GITHUB_STEP_SUMMARY
          echo "**Posted:** ${{ steps.schedule_check.outputs.should_post }}" >> $GITHUB_STEP_SUMMARY
          echo "**Priority:** ${{ steps.schedule_check.outputs.priority }}" >> $GITHUB_STEP_SUMMARY
          echo "**Series:** ${{ steps.schedule_check.outputs.series }}" >> $GITHUB_STEP_SUMMARY
          echo "**Episode:** ${{ steps.schedule_check.outputs.episode_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Content Type:** ${{ steps.schedule_check.outputs.content_type }}" >> $GITHUB_STEP_SUMMARY
          echo "**Target Completion:** ${{ steps.schedule_check.outputs.target_completion }}" >> $GITHUB_STEP_SUMMARY
          echo "**Predicted Completion:** ${{ steps.schedule_check.outputs.predicted_completion }}" >> $GITHUB_STEP_SUMMARY
          echo "**Scheduling Delay:** ${{ steps.schedule_check.outputs.delay_minutes }} minutes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f tmp/delay_log.json ]; then
            echo "### â±ï¸ Delay Statistics" >> $GITHUB_STEP_SUMMARY
            if command -v jq &> /dev/null; then
              STATS=$(jq -r '.statistics // {}' tmp/delay_log.json 2>/dev/null || echo "{}")
              if [ "$STATS" != "{}" ]; then
                AVG_DELAY=$(echo $STATS | jq -r '.average_delay // 0' 2>/dev/null || echo "0")
                MAX_DELAY=$(echo $STATS | jq -r '.max_delay // 0' 2>/dev/null || echo "0")
                ON_TIME=$(echo $STATS | jq -r '.on_time_rate // 0' 2>/dev/null || echo "0")
                echo "- Average delay: ${AVG_DELAY} minutes" >> $GITHUB_STEP_SUMMARY
                echo "- Maximum delay: ${MAX_DELAY} minutes" >> $GITHUB_STEP_SUMMARY
                echo "- On-time rate: ${ON_TIME}%" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          fi
          
          if [ "${{ steps.schedule_check.outputs.has_recommendations }}" == "true" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ’¡ Schedule Recommendations Available" >> $GITHUB_STEP_SUMMARY
            echo "Review recommendations in artifacts: schedule_recommendations.json" >> $GITHUB_STEP_SUMMARY
          fi