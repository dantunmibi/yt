name: Daily Analytics Fetch

on:
  schedule:
    - cron: '0 3 * * *'
  
  workflow_dispatch:
    inputs:
      force_fetch:
        description: 'Force fetch all video analytics'
        required: false
        type: boolean
        default: false

jobs:
  fetch_analytics:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install google-api-python-client google-auth pytz

      - name: Make tmp folder
        run: |
          mkdir -p tmp
          chmod -R 777 tmp

      - name: Restore performance data from cache
        id: cache-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            tmp/content_performance.json
            tmp/upload_history.json
            tmp/schedule_recommendations.json
          key: performance-data-${{ github.run_number }}
          restore-keys: |
            performance-data-

      - name: Fallback to migration artifact if cache empty
        if: steps.cache-restore.outputs.cache-hit != 'true'
        run: |
          echo "‚ö†Ô∏è Cache not found, checking for migration artifact..."
          
          # Download the migrated artifact from the successful migration run
          # Run ID: 19185207383 (your successful migration)
          
          echo "üì• Attempting to download migration artifact..."
        continue-on-error: true

      - name: Download migration artifact (fallback)
        if: steps.cache-restore.outputs.cache-hit != 'true'
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: migrated-performance-data
          run-id: ${{ inputs.artifact_run_id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          path: tmp/

      - name: Verify we have performance data
        run: |
          if [ -f tmp/content_performance.json ]; then
            echo "‚úÖ Performance data found"
            echo "Source: $(if [ -n "${{ steps.cache-restore.outputs.cache-hit }}" ]; then echo "Cache"; else echo "Migration artifact"; fi)"
            echo "Size: $(wc -c < tmp/content_performance.json) bytes"
            
            # Quick structure check
            if grep -q "completion_rate_24h" tmp/content_performance.json; then
              echo "‚úÖ Unified structure verified"
            else
              echo "‚ö†Ô∏è Data structure may need verification"
            fi
          else
            echo "‚ö†Ô∏è No performance data available"
            echo "This is normal for first-time setup"
            echo "Future uploads will populate this data"
          fi

      - name: Fetch YouTube Analytics
        env:
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
        run: python .github/scripts/fetch_youtube_analytics.py

      - name: Generate recommendations
        run: python .github/scripts/track_performance.py

      - name: Save performance data
        uses: actions/cache/save@v4
        if: always()
        with:
          path: |
            tmp/content_performance.json
            tmp/upload_history.json
            tmp/schedule_recommendations.json
          key: performance-data-${{ github.run_number }}

      - name: Upload analytics report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: analytics-report-${{ github.run_number }}
          path: |
            tmp/content_performance.json
            tmp/schedule_recommendations.json
            tmp/delay_log.json
          retention-days: 90

      - name: Summary
        if: always()
        run: |
          echo "## üìä Daily Analytics Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f tmp/content_performance.json ]; then
            echo "### ‚úÖ Performance Data Loaded" >> $GITHUB_STEP_SUMMARY
            
            if [ -n "${{ steps.cache-restore.outputs.cache-hit }}" ]; then
              echo "**Source:** Cache (key: \`${{ steps.cache-restore.outputs.cache-matched-key }}\`)" >> $GITHUB_STEP_SUMMARY
            else
              echo "**Source:** Migration artifact (first-time load)" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Performance by Content Type:" >> $GITHUB_STEP_SUMMARY
            
            if command -v jq &> /dev/null; then
              for type in $(jq -r 'keys[]' tmp/content_performance.json 2>/dev/null || echo ""); do
                AVG=$(jq -r ".[\"$type\"].average_completion // 0" tmp/content_performance.json)
                TOTAL=$(jq -r ".[\"$type\"].total_uploads // 0" tmp/content_performance.json)
                echo "- **$type**: ${AVG}% avg completion ($TOTAL uploads)" >> $GITHUB_STEP_SUMMARY
              done
            fi
          else
            echo "### ‚ö†Ô∏è No Performance Data Yet" >> $GITHUB_STEP_SUMMARY
            echo "Performance tracking will begin with the next upload." >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f tmp/schedule_recommendations.json ]; then
            RECS=$(jq -r '.pending_recommendations | length' tmp/schedule_recommendations.json 2>/dev/null || echo "0")
            if [ "$RECS" != "0" ] && [ "$RECS" != "null" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### üí° $RECS Schedule Recommendations" >> $GITHUB_STEP_SUMMARY
              echo "Review in artifacts: \`analytics-report-${{ github.run_number }}\`" >> $GITHUB_STEP_SUMMARY
            fi
          fi