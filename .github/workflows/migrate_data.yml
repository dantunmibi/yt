name: ðŸ”„ Migrate Performance Data (ONE-TIME)

on:
  workflow_dispatch:
    inputs:
      artifact_run_id:
        description: 'Backfill workflow run ID (find in URL of backfill run)'
        required: true
        type: string

jobs:
  migrate:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies  # â† ADD THIS NEW STEP
        run: |
          python -m pip install --upgrade pip
          pip install pytz
      
      - name: Make tmp folder
        run: mkdir -p tmp
      
      - name: Download backfill artifact
        uses: actions/download-artifact@v4
        with:
          name: backfill-results
          run-id: ${{ inputs.artifact_run_id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          path: tmp/
      
      - name: Verify artifact downloaded
        run: |
          echo "ðŸ“¦ Checking downloaded files..."
          ls -lah tmp/
          
          if [ -f tmp/content_performance.json ]; then
            echo "âœ… Found content_performance.json"
            echo "File size: $(du -h tmp/content_performance.json)"
            
            echo ""
            echo "ðŸ“Š Checking current structure..."
            
            if grep -q "\"completion_rate\":" tmp/content_performance.json; then
              echo "âš ï¸ Has OLD structure (completion_rate)"
              echo "   Migration NEEDED"
            fi
            
            if grep -q "completion_rate_24h" tmp/content_performance.json; then
              echo "âœ… Has NEW structure (completion_rate_24h)"
              echo "   May already be migrated"
            fi
            
            echo ""
            echo "Sample structure:"
            cat tmp/content_performance.json | head -n 30
          else
            echo "âŒ content_performance.json not found in artifact"
            echo ""
            echo "Contents of tmp/:"
            ls -la tmp/
            exit 1
          fi
      
      - name: Run migration script
        run: python .github/scripts/migrate_performance_data.py
      
      - name: Verify migration success
        run: |
          echo "ðŸ” VERIFICATION CHECKS:"
          echo "======================================"
          
          # Check 1: New fields exist
          if grep -q "completion_rate_24h" tmp/content_performance.json; then
            echo "âœ… CHECK 1: Found 'completion_rate_24h' field"
          else
            echo "âŒ CHECK 1: FAILED - Missing 'completion_rate_24h'"
            exit 1
          fi
          
          # Check 2: Old fields removed
          if grep -q "\"completion_rate\":" tmp/content_performance.json; then
            echo "âŒ CHECK 2: FAILED - Still has old 'completion_rate' field"
            exit 1
          else
            echo "âœ… CHECK 2: Old 'completion_rate' field removed"
          fi
          
          # Check 3: views_24h exists
          if grep -q "views_24h" tmp/content_performance.json; then
            echo "âœ… CHECK 3: Found 'views_24h' field"
          else
            echo "âŒ CHECK 3: FAILED - Missing 'views_24h'"
            exit 1
          fi
          
          # Check 4: Status updated
          if grep -q "analytics_available" tmp/content_performance.json; then
            echo "âœ… CHECK 4: Status updated to 'analytics_available'"
          else
            echo "âš ï¸ CHECK 4: WARNING - No 'analytics_available' status found"
          fi
          
          echo ""
          echo "======================================"
          echo "âœ… ALL CHECKS PASSED!"
          echo "======================================"
          echo ""
          echo "ðŸ“Š Sample migrated upload:"
          cat tmp/content_performance.json | grep -A 15 "completion_rate_24h" | head -n 20
      
      - name: Upload migrated data
        uses: actions/upload-artifact@v4
        with:
          name: migrated-performance-data
          path: |
            tmp/content_performance.json
            tmp/content_performance_BACKUP.json
          retention-days: 90
      
      - name: Save to cache (unified key)
        uses: actions/cache/save@v4
        with:
          path: tmp/content_performance.json
          key: performance-data-${{ github.run_number }}
      
      - name: Summary
        run: |
          echo "## âœ… Migration Complete!" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ”„ Changes Made:" >> $GITHUB_STEP_SUMMARY
          echo "- \`completion_rate\` â†’ \`completion_rate_24h\`" >> $GITHUB_STEP_SUMMARY
          echo "- \`views\` â†’ \`views_24h\`" >> $GITHUB_STEP_SUMMARY
          echo "- \`status: backfilled\` â†’ \`status: analytics_available\`" >> $GITHUB_STEP_SUMMARY
          echo "- Added \`analytics_fetched_at\` timestamps" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¥ Artifacts:" >> $GITHUB_STEP_SUMMARY
          echo "- Download \`migrated-performance-data-${{ github.run_number }}\` to verify" >> $GITHUB_STEP_SUMMARY
          echo "- Backup saved as \`content_performance_BACKUP.json\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ’¾ Cache:" >> $GITHUB_STEP_SUMMARY
          echo "- Saved with key: \`performance-data-${{ github.run_number }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Daily analytics will find this data" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸŽ¯ Next Steps:" >> $GITHUB_STEP_SUMMARY
          echo "1. Update workflow files (backfill_analytics.yml, daily_analytics.yml)" >> $GITHUB_STEP_SUMMARY
          echo "2. Update backfill_analytics.py script" >> $GITHUB_STEP_SUMMARY
          echo "3. Test daily_analytics workflow" >> $GITHUB_STEP_SUMMARY